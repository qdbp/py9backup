#! /bin/python3
"""
Dead simple backup functionality.
"""
import os
import os.path as osp
import re
import string
import sys
import tarfile
import tempfile as tmp
from collections import defaultdict
from datetime import date
from functools import lru_cache
from glob import iglob
from heapq import merge
from itertools import groupby
from pathlib import Path
from shutil import copy as fcopy, rmtree
from traceback import format_stack
from typing import Dict, Generator, Iterable, List, Set, Tuple

import click
from click import echo


def die(msg):
    echo(msg, file=sys.stderr)
    sys.exit(-1)


def soft_assert(expr, msg):
    if not bool(expr):
        die(
            "The program has encountered an invalid state. "
            "Please report the following trace as an issue at "
            "https://github.com/qdbp/py9backup\nMessage:\n" +
            msg + '\n' + format_stack()
        )


ALLOWABLE_CHARS = set(string.ascii_letters) | set(string.digits) | {'_'}
CONFIG_DIR = Path('~/.config/py9backup/').expanduser()


@lru_cache(maxsize=1 << 10)
def is_segment_glob(segment: str):
    return bool(re.search(r'(?<!\\)\*', segment))


def gop_prio(path: str) -> int:
    """
    Calculates the priority of a glob or path.

    Returns:
         the number of non-glob path segments in the path.

    Args:
        path: path or glob

    """
    if path == '/':
        return 0
    segments = path.strip('/').split('/')
    return sum([1 - int(is_segment_glob(s)) for s in segments])


def path_depth(path: str) -> int:
    return path.strip('/').count('/')


class RichPath:
    """
    A path or collection of paths with some metadata related to backup
    functionality.
    """

    _FLAGS_LEN = 5
    _FLAGS = [
        (0, 'x', 'exclude'),
        (1, '?', 'sticky'),
        (2, 'g', 'is_glob'),
    ]

    @classmethod
    def parse(cls, raw_line):
        flags = raw_line[:cls._FLAGS_LEN]
        path = raw_line[cls._FLAGS_LEN + 1:].strip()

        fdict = {}
        for ix, char, kwarg in cls._FLAGS:
            if flags[ix] == char:
                fdict[kwarg] = True

        return cls(path, **fdict)

    @property
    def path(self):
        if self.is_glob:
            raise ValueError('A glob-type RichPath has no single path')
        else:
            return self.raw_entry

    def sorted_iter_prio_path(self) -> \
            Generator[Tuple[int, int, str], None, None]:

        """
        Generates the paths of this RP according to their priority.

        Yields:
            Tuples of the form (path_depth, glob_prio, is_include, path)
            suitable for inclusion in order.
        """

        iincl = 1 - int(self.exclude)
        gop = self.raw_entry

        # if the segment is not a glob, treat it like a regular path
        # with glob priority equal to its depth (thus overriding any globs
        # that also match it)
        if not is_segment_glob(gop):
            yield (path_depth(gop), gop, path_depth(gop), iincl)
            return
        else:
            glob_prio = gop_prio(gop)
            yield from iter(sorted([
                (path_depth(path), path, glob_prio, iincl)
                for path in iglob(gop, recursive=True)
            ]))

    def __init__(self, path_str, *, exclude=False,
                 sticky=False, is_glob=False):
        """
        Arguments:
            exclude:
                mark the file or path as being excluded rather than included.
            sticky:
                mark the file or path to persist in the database even if it
                does not exist.
            is_glob:
                mark the path as a glob to be expanded at gather time.
        """

        self.exclude = exclude
        self.sticky = sticky
        self.is_glob = is_glob

        self.raw_entry = Path(path_str).expanduser().absolute().as_posix()

    def __eq__(self, other):
        return self.raw_entry == other.raw_entry

    def __lt__(self, other):
        if self.is_glob ^ other.is_glob:
            return self.is_glob
        else:
            return self.raw_entry < other.raw_entry

    def __str__(self):
        base = [' '] * (self._FLAGS_LEN + 1)
        for ix, char, kwarg in self._FLAGS:
            if getattr(self, kwarg):
                base[ix] = char

        return ''.join(base) + str(self.raw_entry)

    # include only the path in the hash, so that the same path with
    # different flags will intentionally collide in sets/dicts. This
    # makes overwriting the flags easy and enforces a uniqueness invariant.
    def __hash__(self):
        return hash(self.raw_entry)


def canonicalize_group_name(group):
    group = group.lower()
    if set(group) - ALLOWABLE_CHARS:
        die('Illegal characters in group name.')
    return group


def get_backup_fp(fp: Path) -> Path:
    return Path(fp.parent).joinpath('.' + fp.stem + '.bkp')


def get_group_manifest_file(group: str, need=True, check_backup=True) -> Path:
    """
    Get the path of the file storing the backup manifest for the group.
    """
    group = canonicalize_group_name(group)

    fp = CONFIG_DIR.joinpath(f'{group}.txt')
    fp_bkp = get_backup_fp(fp)

    if not fp.exists() or fp.stat().st_size == 0:
        if fp_bkp.exists() and fp_bkp.stat().st_size > 0 and check_backup:
            restore = click.confirm(
                f'The group "{group}" was not found, but a backup file was. '
                'Would you like to restore the backup file?',
                default=True,
            )
            if restore:
                fcopy(fp_bkp.as_posix(), fp.as_posix())
                return fp

        if need:
            die(f'Group "{group}" does not exist or is empty.')
        else:
            fp.touch()

    return fp


def get_group_rps(group: str, need=False) -> List[RichPath]:
    fp = get_group_manifest_file(group, need=need)
    rps = []
    with fp.open('r') as f:
        for line in f:
            rps.append(RichPath.parse(line))

    return rps


def commit_group_rps(group: str, rps: Iterable[RichPath]) -> None:
    """
    Atomically commit the passed rps as the new contents of the group file.

    Does NOT append or merge, that is the responsibility of the caller.
    """

    fp = get_group_manifest_file(group, need=False, check_backup=False)
    tfd, tfn = tmp.mkstemp(text=True)

    if fp.stat().st_size > 0:
        fp_bkp = get_backup_fp(fp)
        fcopy(fp.as_posix(), fp_bkp.as_posix())

    with open(tfd, 'w') as tf:
        for rp in sorted(set(rps)):
            if rp.is_glob or rp.sticky or osp.exists(rp.path):
                echo(rp, file=tf)

    fcopy(tfn, str(fp))
    os.remove(tfn)


def gather_effective_files(rps: Iterable[RichPath]) -> List[str]:
    """
    Converts a collection of include/exclude paths to a minimal collection
    of include-only paths.
    """

    # sort all paths by depth
    included_by_depth: Dict[int, Set[str]] = defaultdict(set)

    def get_highest_prio_by_depth():

        all_by_prio = merge(*[rp.sorted_iter_prio_path() for rp in rps])

        for key, group in groupby(all_by_prio, key=lambda z: z[:2]):

            highest_prio = None
            for x in group:
                highest_prio = x

            yield highest_prio

    root_depth = None

    for cur_depth, cur_path, _, is_incl in get_highest_prio_by_depth():

        # get the highest we need to look in loop
        if root_depth is None:
            root_depth = cur_depth

        if not is_incl:
            # exclusions force explicit expansion in each level above them
            for dx in range(root_depth, cur_depth):
                prefix = None
                for candidate_prefix in included_by_depth[dx]:
                    if cur_path.startswith(candidate_prefix):
                        prefix = candidate_prefix
                        break
                if prefix is None:
                    continue

                # remove higher-level path in favour of fragments
                included_by_depth[dx].remove(prefix)
                included_by_depth[dx + 1] |= \
                    {str(x) for x in Path(prefix).iterdir()}

            # exclude actual exclusion
            included_by_depth[cur_depth].discard(cur_path)

        else:
            # exclude redundant paths
            # this only works because of depth sorting in outer loop!
            for dx in range(root_depth, cur_depth):
                if any([cur_path.startswith(p) for p in included_by_depth[dx]]):
                    break
            else:
                included_by_depth[cur_depth].add(cur_path)

    out: Set[str] = set()
    for fns in included_by_depth.values():
        out |= fns

    return sorted(out)


@click.command(name='add')
@click.argument('group', nargs=1)
@click.argument('paths', nargs=-1)
@click.option(
    '--allow-nx', is_flag=True, default=False,
    help=(
            'Allows nonexistent entries and persists them until explicit '
            'deletion. Otherwise, nonexistent entries are dropped.'
    )
)
@click.option(
    '--exclude', is_flag=True, default=False,
    help=(
            'Excludes the file or path. Overrides more general inclusions. '
            'Overriden by more specific inclusions.'
    )
)
@click.option(
    '--glob/--no-glob', is_flag=True, default=None,
    help=(
            'If true, the path will be interpreted as a glob. If false, it '
            'will be interpreted literally. If unset, the path will be '
            'treated as a glob iff it contains an unescaped "*".'
    )
)
def add_files(group, paths, *, exclude, allow_nx, glob):
    """
    Adds a path to be tracked under a group.
    """
    group = canonicalize_group_name(group)
    rps = set(get_group_rps(group))

    new_rps = set()
    for path in paths:

        if glob is None:
            glob = is_segment_glob(path)

        if not (allow_nx or osp.isfile(path) or osp.isdir(path) or glob):
            echo(
                f'Path "{path}" does not exist. Ignoring. '
                'Pass --allow-nx to force persistent inclusion.'
            )
            continue

        new_rp = RichPath(path, exclude=exclude, sticky=allow_nx, is_glob=glob)
        new_rps.add(new_rp)

    # order is important
    rps = new_rps | rps
    commit_group_rps(group, rps)


@click.command('show')
@click.argument('group')
@click.option(
    '--full', is_flag=True, default=False,
    help='show every included file explicitly',
)
def show_files(group, *, full):
    """
    Shows all tracked paths for group.
    """
    rps = get_group_rps(group, need=True)
    if not full:
        for rp in rps:
            echo(' ' + str(rp))
    else:
        for fn in gather_effective_files(rps):
            echo('\t' + fn)


@click.command(name='del')
@click.argument('group')
@click.argument('regex')
def del_files(group, regex):
    """
    Removes files from group by regex.

    Python's `re.match` is used, so the regexp should match from the
    beginning of the path. Use ^.* or similar.
    """

    if regex == '.':
        answer = click.confirm(
            '"del ." will delete every file in the group. Did you intend to '
            'delete the current directory instead?',
            default=True,
        )
        if answer:
            regex = os.getcwd()

    path_reg = re.compile(regex)
    rps = get_group_rps(group)

    keep_rps = [rp for rp in rps if not path_reg.search(str(rp))]

    commit_group_rps(group, keep_rps)


@click.command()
@click.argument('group')
@click.argument('command', nargs=-1)
@click.option(
    '--no-xz', default=False, is_flag=True, help='turn off xz compression',
)
@click.option('--name', default=None, help='name to use for the tarball')
def pull(group, command, *, no_xz, name):
    """
    Pulls files into tarball, runs given commands on it.

    First, a tarball containing all of the files in the group is created
    in a temporary directory. It is given a sensible default name, which
    can be overriden with the --name option.

    This action accepts any number of positional parameters, each of which
    is interpreted as a shell command to run. Within these commands, the
    string "{}" is expanded to the name of the newly-created tar file.

    After the commands have been executed, the tarfile is deleted.
    """

    if name is None:
        name = f'backup_{group}_{date.today().isoformat()}'

    tar_mode = 'w' if no_xz else 'w:xz'
    suf = 'tar' if no_xz else 'tar.xz'

    file_paths = gather_effective_files(get_group_rps(group))
    temp_dir = tmp.mkdtemp()
    tar_fn = osp.join(temp_dir, f'{name}.{suf}')

    with tarfile.open(tar_fn, tar_mode) as tar:
        for path in file_paths:
            try:
                tar.add(path.strip())
            except FileNotFoundError:
                echo(f'File {path} not found, skipping.', file=sys.stderr)
            except PermissionError:
                die(f'File {path} needs elevated permissions. Dying.')

    for com in command:
        com = re.sub(r'{}', tar_fn, com)
        os.system(com)

    rmtree(temp_dir, ignore_errors=True)


@click.command('list')
def list_groups():
    """
    List known groups.
    """
    for path in sorted(Path(CONFIG_DIR).glob('*.txt')):
        echo(path.stem)


@click.command()
@click.argument('group')
def forget(group):
    """
    Deletes the registry file for a group. Unless that file itself is
    backed up (as is recommended), this cannot be undone.
    """
    group_path = get_group_manifest_file(group, need=True)

    with group_path.open('r') as f:
        lines = f.readlines()

    message = \
        f'Confirm deletion of group {group} containing {len(lines)} lines' + \
        '\n\t' + lines[0] + '\t...\n\t' + lines[-1] + '\n'

    if click.confirm(message):
        group_path.unlink()


@click.group()
def main():
    """
    Tracks files to be backed up, on a per-group basis.

    The first argument is always the group name, which can be an arbitrary well
    behaving string which serves as an identifier for the collection of paths
    added. This allows different backup flow for different files.
    """
    pass


main.add_command(add_files)
main.add_command(del_files)
main.add_command(forget)
main.add_command(list_groups)
main.add_command(show_files)
main.add_command(pull)

if __name__ == '__main__':

    try:
        CONFIG_DIR.mkdir(exist_ok=True)
    except Exception:
        die(f'Unable to create config directory at {CONFIG_DIR}')

    try:
        main()
    except Exception:
        from traceback import format_exc

        die(
            "The program has encountered an invalid state. "
            "Please report the following trace as an issue at "
            "https://github.com/qdbp/py9backup\nMessage:\n" +
            '\n' + format_exc()
        )
