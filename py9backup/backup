#! /bin/python3
"""
Dead simple backup functionality.
"""
import os
import os.path as osp
import re
import string
import sys
import tarfile
import tempfile as tmp
import configparser as ini
from collections import defaultdict
from datetime import date
from functools import lru_cache
from glob import iglob
from heapq import merge
from itertools import groupby
from pathlib import Path
from shutil import copy as fcopy, rmtree
from traceback import format_stack
from typing import Dict, Generator, Iterable, List, Set, Tuple

import click
from click import echo


DIE_CODE = -1


def die(msg):
    echo(msg, file=sys.stderr)
    sys.exit(DIE_CODE)


def soft_assert(expr, msg):
    if not bool(expr):
        die(
            "The program has encountered an invalid state. "
            "Please report the following trace as an issue at "
            "https://github.com/qdbp/py9backup\nMessage:\n"
            + msg + '\n' + format_stack()
        )


ALLOWABLE_CHARS = set(string.ascii_letters) | set(string.digits) | {'_'}
CONFIG_DIR = Path('~/.config/py9backup/').expanduser()


def load_settings():
    settings_fn = CONFIG_DIR.joinpath('settings.ini')
    settings_fn.touch()

    parser = ini.ConfigParser()
    parser.read(str(settings_fn))

    return parser


@lru_cache(maxsize=1 << 10)
def is_segment_glob(segment: str):
    return bool(re.search(r'(?<!\\)\*', segment))


def gop_prio(path: str) -> int:
    """
    Calculates the priority of a glob or path.

    Returns:
         the number of non-glob path segments in the path.

    Args:
        path: path or glob

    """
    if path == '/':
        return 0
    segments = path.strip('/').split('/')
    return sum([1 - int(is_segment_glob(s)) for s in segments])


def path_depth(path: str) -> int:
    return path.strip('/').count('/')


class RichPath:
    """
    A path or collection of paths with some metadata related to backup
    functionality.
    """

    _FLAGS_LEN = 5
    _FLAGS = [
        (0, 'x', 'exclude'),
        (1, '?', 'sticky'),
        (2, 'g', 'is_glob'),
    ]

    @classmethod
    def parse(cls, raw_line):
        flags = raw_line[:cls._FLAGS_LEN]
        path = raw_line[cls._FLAGS_LEN + 1:].strip()

        fdict = {}
        for ix, char, kwarg in cls._FLAGS:
            if flags[ix] == char:
                fdict[kwarg] = True

        return cls(path, **fdict)

    @property
    def path(self):
        if self.is_glob:
            raise ValueError('A glob-type RichPath has no single path')
        else:
            return self.raw_entry

    def sorted_iter_prio_path(self) -> \
            Generator[Tuple[int, str, int, bool], None, None]:
        """
        Generates the paths of this RP according to their priority.

        Yields:
            Tuples of the form (path_depth, path, glob_prio, is_include)
            suitable for inclusion in order.
        """

        iincl = not self.exclude
        gop = self.raw_entry

        # if the segment is not a glob, treat it like a regular path
        # with glob priority equal to its depth (thus overriding any globs
        # that also match it)
        if not is_segment_glob(gop):
            yield (path_depth(gop), gop, path_depth(gop), iincl)
            return
        else:
            glob_prio = gop_prio(gop)
            yield from iter(sorted([
                (path_depth(path), path, glob_prio, iincl)
                for path in iglob(gop, recursive=True)
            ]))

    def __init__(self, path_str, *, exclude=False,
                 sticky=False, is_glob=False):
        """
        Arguments:
            exclude:
                mark the file or path as being excluded rather than included.
            sticky:
                mark the file or path to persist in the database even if it
                does not exist.
            is_glob:
                mark the path as a glob to be expanded at gather time.
        """

        self.exclude = exclude
        self.sticky = sticky
        self.is_glob = is_glob

        self.raw_entry = Path(path_str).expanduser().absolute().as_posix()

    def __eq__(self, other):
        return self.raw_entry == other.raw_entry

    def __lt__(self, other):
        if self.is_glob ^ other.is_glob:
            return self.is_glob
        else:
            return self.raw_entry < other.raw_entry

    def __str__(self):
        base = [' '] * (self._FLAGS_LEN + 1)
        for ix, char, kwarg in self._FLAGS:
            if getattr(self, kwarg):
                base[ix] = char

        return ''.join(base) + str(self.raw_entry)

    # include only the path in the hash, so that the same path with
    # different flags will intentionally collide in sets/dicts. This
    # makes overwriting the flags easy and enforces a uniqueness invariant.
    def __hash__(self):
        return hash(self.raw_entry)


def canonicalize_group_name(group):
    group = group.lower()
    if set(group) - ALLOWABLE_CHARS:
        die('Illegal characters in group name.')
    return group


def get_backup_fp(fp: Path) -> Path:
    return Path(fp.parent).joinpath('.' + fp.stem + '.bkp')


def get_group_manifest_file(
        group: str,
        need_exist=True,
        check_backup=True
) -> Path:
    """
    Get the path of the file storing the backup manifest for the group.

    Arguments:
        group: group for which to get manifest file
        need_exist: if True, dies if manifest does not exist.
        check_backup: if we would die because of need_*s, check backup first.
            If a backup file exists, prompt to restore.
    """

    group = canonicalize_group_name(group)

    fp = CONFIG_DIR.joinpath(f'{group}.txt')
    fp_bkp = get_backup_fp(fp)

    # conditions not met
    if (need_exist and not fp.exists()):
        if check_backup and fp_bkp.exists():
            msg = f'The group "{group}" was not found, but a backup file '\
                + 'was. Would you like to restore the backup file?'

            if click.confirm(msg, default=True):
                fcopy(fp_bkp.as_posix(), fp.as_posix())
                return fp

        elif need_exist:
            die(f'Group "{group}" does not exist.')

    return fp


def get_group_rps(
        group: str,
        need_exist=False,
) -> List[RichPath]:

    fp = get_group_manifest_file(group, need_exist=need_exist)

    if not fp.exists():
        return []
    else:
        with fp.open('r') as f:
            return [RichPath.parse(line) for line in f]


def commit_group_rps(group: str, rps: Iterable[RichPath]) -> None:
    """
    Atomically commit the passed rps as the new contents of the group file.

    Does NOT append or merge, that is the responsibility of the caller.

    Does not write empty files - empty rps is a noop.
    """

    fp = get_group_manifest_file(group, need_exist=False, check_backup=False)
    tfd, tfn = tmp.mkstemp(text=True)

    if fp.exists() and fp.stat().st_size > 0:
        fp_bkp = get_backup_fp(fp)
        fcopy(str(fp), str(fp_bkp))

    with tmp.NamedTemporaryFile(mode='w') as tf:
        for rp in sorted(set(rps)):
            if rp.is_glob or rp.sticky or osp.exists(rp.path):
                tf.write(str(rp) + '\n')

        tf.flush()
        fcopy(tf.name, str(fp))


def gather_effective_files(rps: Iterable[RichPath]) -> List[str]:
    """
    Converts a collection of include/exclude paths to a minimal collection
    of include-only paths.
    """

    # sort all paths by depth
    included_by_depth: Dict[int, Set[str]] = defaultdict(set)

    def get_highest_prio_by_depth():

        all_by_prio = merge(*[rp.sorted_iter_prio_path() for rp in rps])

        for key, group in groupby(all_by_prio, key=lambda z: z[:2]):

            highest_prio = None
            for x in group:
                highest_prio = x

            yield highest_prio

    root_depth = None

    for cur_depth, cur_path, _, is_incl in get_highest_prio_by_depth():

        # get the highest we need to look in loop
        if root_depth is None:
            root_depth = cur_depth

        if not is_incl:
            # exclusions force explicit expansion in each level above them
            for dx in range(root_depth, cur_depth):
                prefix = None
                for candidate_prefix in included_by_depth[dx]:
                    if cur_path.startswith(candidate_prefix):
                        prefix = candidate_prefix
                        break
                if prefix is None:
                    continue

                # remove higher-level path in favour of fragments
                included_by_depth[dx].remove(prefix)
                included_by_depth[dx + 1] |= \
                    {str(x) for x in Path(prefix).iterdir()}

            # exclude actual exclusion
            included_by_depth[cur_depth].discard(cur_path)

        else:
            # exclude redundant paths
            # this only works because of depth sorting in outer loop!
            for dx in range(root_depth, cur_depth):
                if any([cur_path.startswith(p)
                        for p in included_by_depth[dx]]):
                    break
            else:
                included_by_depth[cur_depth].add(cur_path)

    out: Set[str] = set()
    for fns in included_by_depth.values():
        out |= fns

    return sorted(out)


# # # COMMANDS SECTION


@click.group()
def main():
    """
    Tracks files to be backed up, on a per-group basis.

    The first argument is always the group name, which can be an arbitrary well
    behaving string which serves as an identifier for the collection of paths
    added. This allows different backup flow for different files.
    """
    pass


@main.command(name='add')
@click.argument('group', nargs=1)
@click.argument('paths', nargs=-1)
@click.option(
    '--allow-nx', is_flag=True, default=False,
    help=(
        'Allows nonexistent entries and persists them until explicit '
        'deletion. Otherwise, nonexistent entries are dropped.'
    )
)
@click.option(
    '--exclude', is_flag=True, default=False,
    help=(
        'Excludes the file or path. Overrides more general inclusions. '
        'Overriden by more specific inclusions.'
    )
)
@click.option(
    '--glob/--no-glob', is_flag=True, default=None,
    help=(
        'If true, the path will be interpreted as a glob. If false, it '
        'will be interpreted literally. If unset, the path will be '
        'treated as a glob iff it contains an unescaped "*".'
    )
)
def add_files(group, paths, *, exclude, allow_nx, glob):
    """
    Adds a path to be tracked under a group.
    """
    group = canonicalize_group_name(group)
    rps = set(get_group_rps(group))

    new_rps = set()
    for path in paths:

        if glob is None:
            glob = is_segment_glob(path)

        if not (allow_nx or osp.isfile(path) or osp.isdir(path) or glob):
            echo(
                f'Path "{path}" does not exist. Ignoring. '
                'Pass --allow-nx to force persistent inclusion.'
            )
            continue

        new_rp = RichPath(path, exclude=exclude, sticky=allow_nx, is_glob=glob)
        new_rps.add(new_rp)

    # order is important, we need to favour the new rps in hash conflicts
    rps = new_rps | rps
    commit_group_rps(group, rps)


@main.command('show')
@click.argument('group')
@click.option(
    '--full', is_flag=True, default=False,
    help='show every included file explicitly',
)
def show_files(group, *, full):
    """
    Shows all tracked paths for group.
    """
    rps = get_group_rps(group, need_exist=True)
    if not full:
        for rp in rps:
            echo(' ' + str(rp))
    else:
        for fn in gather_effective_files(rps):
            echo('\t' + fn)


@main.command(name='del')
@click.argument('group')
@click.argument('regex')
def del_files(group, regex):
    """
    Removes files from group by regex.

    Python's `re.match` is used, so the regexp should match from the
    beginning of the path. Use ^.* or similar.
    """

    if regex == '.' and click.confirm(
            '"del ." will delete every file in the group. Did you intend to '
            'delete the current directory instead?',
                default=True):
        regex = os.getcwd()
    elif regex == '..' and click.confirm(
        '"del .." will likely delete every file in the group. Did you'
        'intend to delete the current directory instead?',
            default=True):
        regex = str(Path(os.getcwd()).parent)

    regex.rstrip('/')

    print(regex)

    path_reg = re.compile(regex)
    rps = get_group_rps(group)

    keep_rps = [rp for rp in rps if not path_reg.search(str(rp))]

    print(keep_rps)

    commit_group_rps(group, keep_rps)


@main.command()
@click.argument('group')
@click.argument('commands', nargs=-1)
@click.option(
    '--no-xz', default=False, is_flag=True, help='turn off xz compression',
)
@click.option('--name', default=None, help='name to use for the tarball')
def pull(group, commands, *, no_xz, name) -> None:
    """
    Pulls files into tarball, runs given commands on it.

    First, a tarball containing all of the files in the group is created
    in a temporary directory. It is given a sensible default name, which
    can be overriden with the --name option.

    This action accepts any number of positional parameters, each of which
    is interpreted as a shell command to run. Within these commands, the
    string "{}" is expanded to the name of the newly-created tar file.

    After the commands have been executed, the tarfile is deleted.
    """

    if name is None:
        name = f'backup_{group}_{date.today().isoformat()}'

    tar_mode = 'w' if no_xz else 'w:xz'
    suf = 'tar' if no_xz else 'tar.xz'

    file_paths = gather_effective_files(get_group_rps(group, need_exist=True))

    if len(file_paths) == 0 and not click.confirm(
            f'Group {group} is empty. Continue?', default=False):
        return

    temp_dir = tmp.mkdtemp()
    tar_fn = osp.join(temp_dir, f'{name}.{suf}')

    with tarfile.open(tar_fn, tar_mode) as tar:
        for path in file_paths:
            try:
                tar.add(path.strip())
            except FileNotFoundError:
                echo(f'File {path} not found, skipping.', file=sys.stderr)
            except PermissionError:
                die(f'File {path} needs elevated permissions. Dying.')

    if not commands:
        settings = load_settings()
        try:
            commands = [settings['py9backup']['default_pull_command']]
            click.echo(
                'Running default pull commands:\n\t' + '\n\t'.join(commands)
            )
        except KeyError:
            commands = []

    for com in commands:
        com = re.sub(r'{}', tar_fn, com)
        os.system(com)

    rmtree(temp_dir, ignore_errors=True)


@main.command('list')
def list_groups():
    """
    List known groups.
    """
    for path in sorted(Path(CONFIG_DIR).glob('*.txt')):
        echo(path.stem)


@main.command()
@click.argument('group')
def forget(group):
    """
    Deletes the registry file for a group. Unless that file itself is
    backed up (as is recommended), this cannot be undone.
    """

    group_path = get_group_manifest_file(group, need_exist=True)

    if not group_path.exists():
        return

    with group_path.open('r') as f:
        lines = f.readlines()

    if lines:
        message =\
            f'Confirm deletion of group {group} containing {len(lines)} lines'\
            + '\n\t' + lines[0] + '\t...\n\t' + lines[-1] + '\n'

        if not click.confirm(message, default=False):
            return

    group_path.unlink()


if __name__ == '__main__':

    try:
        CONFIG_DIR.mkdir(exist_ok=True)
    except Exception:
        die(f'Unable to create config directory at {CONFIG_DIR}')

    try:
        main()
    except Exception:
        from traceback import format_exc

        die(
            "The program has encountered an invalid state.\n"
            "Please report the following trace as an issue at "
            "https://github.com/qdbp/py9backup:\n"
            + '\n' + format_exc()
            + "\nI apologize for the inconvenience."
        )
